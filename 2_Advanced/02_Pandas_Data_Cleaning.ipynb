{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "652c2fd4",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/lukebarousse/Python_Data_Analytics_Course/blob/main/2_Advanced/02_Pandas_Data_Cleaning.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ah78BBuvJN8N"
   },
   "source": [
    "# Pandas Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# Loading Data\n",
    "dataset = load_dataset('lukebarousse/data_jobs')\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "# Data Cleanup\n",
    "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ns-Ku67JYIg"
   },
   "source": [
    "### Review\n",
    "\n",
    "This is what we learned in the basics section, this is just a refresher of how we've handled null values before. Feel free to skip this.\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- `df.dropna()`: Drop missing values.\n",
    "\n",
    "##### Examples\n",
    "\n",
    "Here we are only drop values if all of their values are missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 787686 entries, 0 to 787685\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   job_title_short        787686 non-null  object \n",
      " 1   job_title              787685 non-null  object \n",
      " 2   job_location           786638 non-null  object \n",
      " 3   job_via                787678 non-null  object \n",
      " 4   job_schedule_type      774976 non-null  object \n",
      " 5   job_work_from_home     787686 non-null  bool   \n",
      " 6   search_location        787686 non-null  object \n",
      " 7   job_posted_date        787686 non-null  object \n",
      " 8   job_no_degree_mention  787686 non-null  bool   \n",
      " 9   job_health_insurance   787686 non-null  bool   \n",
      " 10  job_country            787636 non-null  object \n",
      " 11  salary_rate            33089 non-null   object \n",
      " 12  salary_year_avg        22046 non-null   float64\n",
      " 13  salary_hour_avg        10648 non-null   float64\n",
      " 14  company_name           787669 non-null  object \n",
      " 15  job_skills             670364 non-null  object \n",
      " 16  job_type_skills        670364 non-null  object \n",
      "dtypes: bool(3), float64(2), object(12)\n",
      "memory usage: 86.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df.dropna(how='all')\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now all we can do is drop values if they're missing. But that's not useful right now because our DataFrame didn't have any. \n",
    "\n",
    "So, what if we wanted to fill the missing values with something else? This is expecially useful so we don't run into errors when dealing with NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fillna\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- `df.fillna()`: Fill missing values\n",
    "\n",
    "#### Examples\n",
    "\n",
    "Let's fill in instances where there's no salary info (aka these columns have NaN values `salary_rate`, `salary_year_avg`, `salary_hour_avg`) with 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to look at a few rows in these 3 columns right now, so we can compare what we've done before to after. \n",
    "\n",
    "We'll use `iloc` to look at the first 10 rows `:20` and the salary information rows `11:14`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>year</td>\n",
       "      <td>425000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>year</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  salary_rate  salary_year_avg  salary_hour_avg\n",
       "0         NaN              NaN              NaN\n",
       "1         NaN              NaN              NaN\n",
       "2        year         425000.0              NaN\n",
       "3         NaN              NaN              NaN\n",
       "4         NaN              NaN              NaN\n",
       "5         NaN              NaN              NaN\n",
       "6        year         180000.0              NaN\n",
       "7         NaN              NaN              NaN\n",
       "8         NaN              NaN              NaN\n",
       "9         NaN              NaN              NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.iloc[:10,11:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fill the values for the 3 columns with 0 using `fillna()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 787686 entries, 0 to 787685\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   job_title_short        787686 non-null  object \n",
      " 1   job_title              787686 non-null  object \n",
      " 2   job_location           787686 non-null  object \n",
      " 3   job_via                787686 non-null  object \n",
      " 4   job_schedule_type      787686 non-null  object \n",
      " 5   job_work_from_home     787686 non-null  bool   \n",
      " 6   search_location        787686 non-null  object \n",
      " 7   job_posted_date        787686 non-null  object \n",
      " 8   job_no_degree_mention  787686 non-null  bool   \n",
      " 9   job_health_insurance   787686 non-null  bool   \n",
      " 10  job_country            787686 non-null  object \n",
      " 11  salary_rate            787686 non-null  object \n",
      " 12  salary_year_avg        787686 non-null  float64\n",
      " 13  salary_hour_avg        787686 non-null  float64\n",
      " 14  company_name           787686 non-null  object \n",
      " 15  job_skills             787686 non-null  object \n",
      " 16  job_type_skills        787686 non-null  object \n",
      "dtypes: bool(3), float64(2), object(12)\n",
      "memory usage: 86.4+ MB\n"
     ]
    }
   ],
   "source": [
    "fill_values = ['salary_rate', 'salary_year_avg', 'salary_hour_avg']\n",
    "df_filled = df_cleaned.fillna(0)\n",
    "df_filled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we compare the results using `iloc` again on our new DataFrame. We see that the previous NaN values in the columns ( `salary_rate`, `salary_year_avg`, `salary_hour_avg`) have been replaced with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>year</td>\n",
       "      <td>425000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>year</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  salary_rate  salary_year_avg  salary_hour_avg\n",
       "0           0              0.0              0.0\n",
       "1           0              0.0              0.0\n",
       "2        year         425000.0              0.0\n",
       "3           0              0.0              0.0\n",
       "4           0              0.0              0.0\n",
       "5           0              0.0              0.0\n",
       "6        year         180000.0              0.0\n",
       "7           0              0.0              0.0\n",
       "8           0              0.0              0.0\n",
       "9           0              0.0              0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled.iloc[:10,11:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Duplicates\n",
    "\n",
    "### Notes\n",
    "\n",
    "* `drop_duplicates()`: Remove duplicate rows.\n",
    "* Analysts will often need to clean up data and one of the most common issues we run into is duplicate values. \n",
    "\n",
    "### Examples\n",
    "\n",
    "Now that we've dealt with NaN values. Let's continue cleaning the data by removing any duplicate rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 787573 entries, 0 to 787685\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   job_title_short        787573 non-null  object \n",
      " 1   job_title              787573 non-null  object \n",
      " 2   job_location           787573 non-null  object \n",
      " 3   job_via                787573 non-null  object \n",
      " 4   job_schedule_type      787573 non-null  object \n",
      " 5   job_work_from_home     787573 non-null  bool   \n",
      " 6   search_location        787573 non-null  object \n",
      " 7   job_posted_date        787573 non-null  object \n",
      " 8   job_no_degree_mention  787573 non-null  bool   \n",
      " 9   job_health_insurance   787573 non-null  bool   \n",
      " 10  job_country            787573 non-null  object \n",
      " 11  salary_rate            787573 non-null  object \n",
      " 12  salary_year_avg        787573 non-null  float64\n",
      " 13  salary_hour_avg        787573 non-null  float64\n",
      " 14  company_name           787573 non-null  object \n",
      " 15  job_skills             787573 non-null  object \n",
      " 16  job_type_skills        787573 non-null  object \n",
      "dtypes: bool(3), float64(2), object(12)\n",
      "memory usage: 92.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_unique = df_filled.drop_duplicates()\n",
    "df_unique.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you compare that with the original DataFrame which had 787686 entries. This new DataFrame `df_unique` has 787577 entries. It removed 109 entries. \n",
    "\n",
    "Now let's see what would happen if we tried to remove duplicates from `job_title`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 235063 entries, 0 to 787685\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   job_title_short        235063 non-null  object \n",
      " 1   job_title              235063 non-null  object \n",
      " 2   job_location           235063 non-null  object \n",
      " 3   job_via                235063 non-null  object \n",
      " 4   job_schedule_type      235063 non-null  object \n",
      " 5   job_work_from_home     235063 non-null  bool   \n",
      " 6   search_location        235063 non-null  object \n",
      " 7   job_posted_date        235063 non-null  object \n",
      " 8   job_no_degree_mention  235063 non-null  bool   \n",
      " 9   job_health_insurance   235063 non-null  bool   \n",
      " 10  job_country            235063 non-null  object \n",
      " 11  salary_rate            235063 non-null  object \n",
      " 12  salary_year_avg        235063 non-null  float64\n",
      " 13  salary_hour_avg        235063 non-null  float64\n",
      " 14  company_name           235063 non-null  object \n",
      " 15  job_skills             235063 non-null  object \n",
      " 16  job_type_skills        235063 non-null  object \n",
      "dtypes: bool(3), float64(2), object(12)\n",
      "memory usage: 27.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_unique = df_filled.drop_duplicates(subset=['job_title'])\n",
    "df_unique.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at it now. It looks like we removed quite a few rows. Now all of these rows have unique `job_title`s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>DevOps Engineer - Big Data/Advanced Analytics</td>\n",
       "      <td>Bari, Metropolitan City of Bari, Italy</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2023-10-24 18:16:15</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Italy</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NTT DATA Italia</td>\n",
       "      <td>['shell', 'python', 'bash', 'mongodb', 'mongod...</td>\n",
       "      <td>{'cloud': ['gcp', 'aws', 'azure'], 'databases'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Co-Op/Intern Software Engineer, Data Ingestion</td>\n",
       "      <td>Vancouver, BC, Canada</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023-05-05 18:37:58</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kinaxis</td>\n",
       "      <td>['java', 'c#', 'mysql', 'oracle', 'docker', 'k...</td>\n",
       "      <td>{'cloud': ['oracle'], 'databases': ['mysql'], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Hybrid - Data Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-07-25 19:07:08</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>year</td>\n",
       "      <td>425000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Durlston Partners</td>\n",
       "      <td>['python']</td>\n",
       "      <td>{'programming': ['python']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hamtramck, MI</td>\n",
       "      <td>via BeBee</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Illinois, United States</td>\n",
       "      <td>2023-11-30 18:05:20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Apexon</td>\n",
       "      <td>['sql', 'r', 'scala', 'java', 'gcp', 'aws', 'h...</td>\n",
       "      <td>{'analyst_tools': ['tableau', 'sap', 'word'], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Lead Engineer (with strong Python) - Remo...</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via Jobgether</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>True</td>\n",
       "      <td>Panama</td>\n",
       "      <td>2023-08-13 18:32:30</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Panama</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FullStack Labs</td>\n",
       "      <td>['python', 'aws', 'tableau', 'looker', 'terraf...</td>\n",
       "      <td>{'analyst_tools': ['tableau', 'looker'], 'asyn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Milford, CT</td>\n",
       "      <td>via Snagajob</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>California, United States</td>\n",
       "      <td>2023-07-28 18:06:44</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Franchise World Headquarters, LLC</td>\n",
       "      <td>['python', 'nosql', 'sql', 'aws', 'redshift', ...</td>\n",
       "      <td>{'cloud': ['aws', 'redshift'], 'other': ['flow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Texas</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-03-06 18:51:56</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>United States</td>\n",
       "      <td>year</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Trepp, Inc.</td>\n",
       "      <td>['sql', 'python', 'java', 'scala', 'aws', 'spa...</td>\n",
       "      <td>{'cloud': ['aws'], 'libraries': ['spark'], 'ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Applied Mathematician, Scientist, or Engineer</td>\n",
       "      <td>Copenhagen, Denmark</td>\n",
       "      <td>via BeBee Danmark</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2023-07-12 18:24:10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Signaloid</td>\n",
       "      <td>['c', 'python', 'github', 'zoom']</td>\n",
       "      <td>{'other': ['github'], 'programming': ['c', 'py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Sr. Big Data Engineer with Data Bricks, Loc - ...</td>\n",
       "      <td>Quincy, MA</td>\n",
       "      <td>via ZipRecruiter</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>California, United States</td>\n",
       "      <td>2023-05-25 18:05:51</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Apptad Inc</td>\n",
       "      <td>['sql', 'python', 'aws', 'databricks', 'spark'...</td>\n",
       "      <td>{'cloud': ['aws', 'databricks'], 'libraries': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Azure Data Engineer</td>\n",
       "      <td>Warren, NJ</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>False</td>\n",
       "      <td>California, United States</td>\n",
       "      <td>2023-09-20 18:05:42</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Saransh Inc</td>\n",
       "      <td>['sql', 'azure', 'spark']</td>\n",
       "      <td>{'cloud': ['azure'], 'libraries': ['spark'], '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        job_title_short                                          job_title  \\\n",
       "0         Data Engineer      DevOps Engineer - Big Data/Advanced Analytics   \n",
       "1         Data Engineer     Co-Op/Intern Software Engineer, Data Ingestion   \n",
       "2         Data Engineer                             Hybrid - Data Engineer   \n",
       "3        Data Scientist                                     Data Scientist   \n",
       "4         Data Engineer  Data Lead Engineer (with strong Python) - Remo...   \n",
       "5  Senior Data Engineer                               Senior Data Engineer   \n",
       "6         Data Engineer                                      Data Engineer   \n",
       "7          Data Analyst      Applied Mathematician, Scientist, or Engineer   \n",
       "8  Senior Data Engineer  Sr. Big Data Engineer with Data Bricks, Loc - ...   \n",
       "9         Data Engineer                                Azure Data Engineer   \n",
       "\n",
       "                             job_location            job_via  \\\n",
       "0  Bari, Metropolitan City of Bari, Italy       via LinkedIn   \n",
       "1                   Vancouver, BC, Canada       via LinkedIn   \n",
       "2                            New York, NY       via LinkedIn   \n",
       "3                           Hamtramck, MI          via BeBee   \n",
       "4                                Anywhere      via Jobgether   \n",
       "5                             Milford, CT       via Snagajob   \n",
       "6                                   Texas       via LinkedIn   \n",
       "7                     Copenhagen, Denmark  via BeBee Danmark   \n",
       "8                              Quincy, MA   via ZipRecruiter   \n",
       "9                              Warren, NJ       via LinkedIn   \n",
       "\n",
       "  job_schedule_type  job_work_from_home            search_location  \\\n",
       "0         Full-time               False                      Italy   \n",
       "1         Full-time               False                     Canada   \n",
       "2         Full-time               False                      Sudan   \n",
       "3         Full-time               False    Illinois, United States   \n",
       "4         Full-time                True                     Panama   \n",
       "5         Full-time               False  California, United States   \n",
       "6         Full-time               False       Texas, United States   \n",
       "7         Full-time               False                    Denmark   \n",
       "8         Full-time               False  California, United States   \n",
       "9        Contractor               False  California, United States   \n",
       "\n",
       "       job_posted_date  job_no_degree_mention  job_health_insurance  \\\n",
       "0  2023-10-24 18:16:15                   True                 False   \n",
       "1  2023-05-05 18:37:58                  False                 False   \n",
       "2  2023-07-25 19:07:08                  False                 False   \n",
       "3  2023-11-30 18:05:20                  False                 False   \n",
       "4  2023-08-13 18:32:30                  False                 False   \n",
       "5  2023-07-28 18:06:44                  False                 False   \n",
       "6  2023-03-06 18:51:56                  False                  True   \n",
       "7  2023-07-12 18:24:10                  False                 False   \n",
       "8  2023-05-25 18:05:51                   True                 False   \n",
       "9  2023-09-20 18:05:42                   True                 False   \n",
       "\n",
       "     job_country salary_rate  salary_year_avg  salary_hour_avg  \\\n",
       "0          Italy           0              0.0              0.0   \n",
       "1         Canada           0              0.0              0.0   \n",
       "2          Sudan        year         425000.0              0.0   \n",
       "3  United States           0              0.0              0.0   \n",
       "4         Panama           0              0.0              0.0   \n",
       "5  United States           0              0.0              0.0   \n",
       "6  United States        year         180000.0              0.0   \n",
       "7        Denmark           0              0.0              0.0   \n",
       "8  United States           0              0.0              0.0   \n",
       "9  United States           0              0.0              0.0   \n",
       "\n",
       "                        company_name  \\\n",
       "0                    NTT DATA Italia   \n",
       "1                            Kinaxis   \n",
       "2                  Durlston Partners   \n",
       "3                             Apexon   \n",
       "4                     FullStack Labs   \n",
       "5  Franchise World Headquarters, LLC   \n",
       "6                        Trepp, Inc.   \n",
       "7                          Signaloid   \n",
       "8                         Apptad Inc   \n",
       "9                        Saransh Inc   \n",
       "\n",
       "                                          job_skills  \\\n",
       "0  ['shell', 'python', 'bash', 'mongodb', 'mongod...   \n",
       "1  ['java', 'c#', 'mysql', 'oracle', 'docker', 'k...   \n",
       "2                                         ['python']   \n",
       "3  ['sql', 'r', 'scala', 'java', 'gcp', 'aws', 'h...   \n",
       "4  ['python', 'aws', 'tableau', 'looker', 'terraf...   \n",
       "5  ['python', 'nosql', 'sql', 'aws', 'redshift', ...   \n",
       "6  ['sql', 'python', 'java', 'scala', 'aws', 'spa...   \n",
       "7                  ['c', 'python', 'github', 'zoom']   \n",
       "8  ['sql', 'python', 'aws', 'databricks', 'spark'...   \n",
       "9                          ['sql', 'azure', 'spark']   \n",
       "\n",
       "                                     job_type_skills  \n",
       "0  {'cloud': ['gcp', 'aws', 'azure'], 'databases'...  \n",
       "1  {'cloud': ['oracle'], 'databases': ['mysql'], ...  \n",
       "2                        {'programming': ['python']}  \n",
       "3  {'analyst_tools': ['tableau', 'sap', 'word'], ...  \n",
       "4  {'analyst_tools': ['tableau', 'looker'], 'asyn...  \n",
       "5  {'cloud': ['aws', 'redshift'], 'other': ['flow...  \n",
       "6  {'cloud': ['aws'], 'libraries': ['spark'], 'ot...  \n",
       "7  {'other': ['github'], 'programming': ['c', 'py...  \n",
       "8  {'cloud': ['aws', 'databricks'], 'libraries': ...  \n",
       "9  {'cloud': ['azure'], 'libraries': ['spark'], '...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our example we don't really need to remove any duplicates right now, but it's important to understand the concept."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO7QGE4EmxtJp+NvT7AZdbk",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
